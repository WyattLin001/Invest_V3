//
//  AIContentModerationService.swift
//  Invest_V3
//
//  Created by AI Assistant on 2025/8/1.
//  AI å…§å®¹å¯©æ ¸æœå‹™ - æä¾› AI ç”Ÿæˆæ–‡ç« çš„å®‰å…¨æ€§æª¢æŸ¥å’Œå…§å®¹ç®¡åˆ¶
//

import Foundation
import SwiftUI

// MARK: - å…§å®¹å¯©æ ¸çµæžœ
struct ContentModerationResult {
    let isApproved: Bool
    let riskLevel: ContentRiskLevel
    let warnings: [ContentWarning]
    let suggestions: [String]
    let moderationScore: Double // 0-1ï¼Œè¶Šé«˜è¶Šå®‰å…¨
    
    var canAutoPublish: Bool {
        return isApproved && riskLevel == .low && moderationScore >= 0.85
    }
}

// MARK: - å…§å®¹é¢¨éšªç­‰ç´š
enum ContentRiskLevel: String, CaseIterable {
    case low = "low"
    case medium = "medium"
    case high = "high"
    case critical = "critical"
    
    var displayName: String {
        switch self {
        case .low: return "ä½Žé¢¨éšª"
        case .medium: return "ä¸­ç­‰é¢¨éšª"
        case .high: return "é«˜é¢¨éšª"
        case .critical: return "åš´é‡é¢¨éšª"
        }
    }
    
    var color: Color {
        switch self {
        case .low: return .green
        case .medium: return .orange
        case .high: return .red
        case .critical: return .purple
        }
    }
}

// MARK: - å…§å®¹è­¦å‘Š
struct ContentWarning {
    let type: WarningType
    let message: String
    let severity: WarningSeverity
    let location: String? // æ–‡ç« ä¸­çš„ä½ç½®æˆ–æ®µè½
}

enum WarningType: String, CaseIterable {
    case inappropriateLanguage = "inappropriate_language"
    case financialAdvice = "financial_advice"
    case misleadingClaims = "misleading_claims"
    case copyrightIssue = "copyright_issue"
    case dataAccuracy = "data_accuracy"
    case regulatory = "regulatory"
    case spam = "spam"
    
    var displayName: String {
        switch self {
        case .inappropriateLanguage: return "ä¸ç•¶ç”¨è©ž"
        case .financialAdvice: return "æŠ•è³‡å»ºè­°é¢¨éšª"
        case .misleadingClaims: return "èª¤å°Žæ€§è²æ˜Ž"
        case .copyrightIssue: return "ç‰ˆæ¬Šå•é¡Œ"
        case .dataAccuracy: return "æ•¸æ“šæº–ç¢ºæ€§"
        case .regulatory: return "æ³•è¦åˆè¦"
        case .spam: return "åžƒåœ¾å…§å®¹"
        }
    }
}

enum WarningSeverity: String, CaseIterable {
    case info = "info"
    case warning = "warning"
    case error = "error"
    case critical = "critical"
    
    var color: Color {
        switch self {
        case .info: return .blue
        case .warning: return .orange
        case .error: return .red
        case .critical: return .purple
        }
    }
}

// MARK: - AI å…§å®¹å¯©æ ¸æœå‹™
@MainActor
class AIContentModerationService: ObservableObject {
    static let shared = AIContentModerationService()
    
    // MARK: - Published Properties
    @Published var isProcessing = false
    @Published var moderationHistory: [ModerationRecord] = []
    
    // MARK: - Properties
    private let supabaseService = SupabaseService.shared
    
    // å…§å®¹å¯©æ ¸é…ç½®
    private let riskKeywords = [
        "financial_advice": ["å»ºè­°è³¼è²·", "æŽ¨è–¦è²·å…¥", "å¿…è²·", "å¿…è³º", "ä¿è­‰ç²åˆ©"],
        "inappropriate": ["è©é¨™", "æ¬ºé¨™", "æ“ç¸±", "å…§ç·š", "éžæ³•"],
        "regulatory": ["è­‰åˆ¸", "é‡‘ç®¡æœƒ", "é•æ³•", "ç›£ç®¡"]
    ]
    
    private init() {}
    
    // MARK: - å…¬å…±æ–¹æ³•
    
    /// å¯©æ ¸ AI ç”Ÿæˆçš„æ–‡ç« å…§å®¹
    func moderateAIArticle(_ article: Article) async throws -> ContentModerationResult {
        print("ðŸ” [AIContentModerationService] é–‹å§‹å¯©æ ¸ AI æ–‡ç« : \(article.title)")
        isProcessing = true
        
        defer {
            isProcessing = false
        }
        
        var warnings: [ContentWarning] = []
        var moderationScore: Double = 1.0
        
        // 1. åŸºç¤Žå…§å®¹æª¢æŸ¥
        warnings.append(contentsOf: checkBasicContent(article))
        
        // 2. é‡‘èžå»ºè­°é¢¨éšªæª¢æŸ¥
        warnings.append(contentsOf: checkFinancialAdviceRisk(article))
        
        // 3. é—œéµå­—æª¢æŸ¥
        warnings.append(contentsOf: checkRiskKeywords(article))
        
        // 4. æ•¸æ“šæº–ç¢ºæ€§æª¢æŸ¥
        warnings.append(contentsOf: checkDataAccuracy(article))
        
        // 5. æ³•è¦åˆè¦æª¢æŸ¥
        warnings.append(contentsOf: checkRegulatoryCompliance(article))
        
        // è¨ˆç®—é¢¨éšªç­‰ç´šå’Œå¯©æ ¸åˆ†æ•¸
        let riskLevel = calculateRiskLevel(warnings: warnings)
        moderationScore = calculateModerationScore(warnings: warnings, riskLevel: riskLevel)
        
        let result = ContentModerationResult(
            isApproved: moderationScore >= 0.6 && riskLevel != .critical,
            riskLevel: riskLevel,
            warnings: warnings,
            suggestions: generateSuggestions(warnings: warnings),
            moderationScore: moderationScore
        )
        
        // è¨˜éŒ„å¯©æ ¸çµæžœ
        let record = ModerationRecord(
            articleId: article.id,
            articleTitle: article.title,
            result: result,
            moderatedAt: Date(),
            moderator: "AI System"
        )
        moderationHistory.append(record)
        
        // ä¿å­˜å¯©æ ¸è¨˜éŒ„åˆ°è³‡æ–™åº«
        try await saveModerationRecord(record)
        
        print("âœ… [AIContentModerationService] å¯©æ ¸å®Œæˆ - é¢¨éšªç­‰ç´š: \(riskLevel.displayName), åˆ†æ•¸: \(String(format: "%.2f", moderationScore))")
        
        return result
    }
    
    /// æ‰¹é‡å¯©æ ¸å¾…å¯©æ ¸çš„ AI æ–‡ç« 
    func moderatePendingAIArticles() async throws -> [UUID: ContentModerationResult] {
        let pendingArticles = try await supabaseService.getPendingAIArticles()
        var results: [UUID: ContentModerationResult] = [:]
        
        for article in pendingArticles {
            do {
                let result = try await moderateAIArticle(article)
                results[article.id] = result
                
                // å¦‚æžœå¯ä»¥è‡ªå‹•ç™¼å¸ƒï¼Œæ›´æ–°ç‹€æ…‹
                if result.canAutoPublish {
                    try await supabaseService.updateArticleStatus(article.id, status: .published)
                    print("ðŸš€ [AIContentModerationService] æ–‡ç« è‡ªå‹•ç™¼å¸ƒ: \(article.title)")
                }
                
            } catch {
                print("âŒ [AIContentModerationService] å¯©æ ¸æ–‡ç« å¤±æ•—: \(article.title) - \(error.localizedDescription)")
            }
        }
        
        return results
    }
    
    /// ç²å–å¯©æ ¸çµ±è¨ˆ
    func getModerationStats() -> ModerationStats {
        let total = moderationHistory.count
        let approved = moderationHistory.filter { $0.result.isApproved }.count
        let autoPublished = moderationHistory.filter { $0.result.canAutoPublish }.count
        
        let riskDistribution = Dictionary(grouping: moderationHistory) { $0.result.riskLevel }
            .mapValues { $0.count }
        
        return ModerationStats(
            totalReviewed: total,
            approved: approved,
            autoPublished: autoPublished,
            riskDistribution: riskDistribution
        )
    }
    
    // MARK: - ç§æœ‰æ–¹æ³•
    
    /// åŸºç¤Žå…§å®¹æª¢æŸ¥
    private func checkBasicContent(_ article: Article) -> [ContentWarning] {
        var warnings: [ContentWarning] = []
        
        // æª¢æŸ¥æ¨™é¡Œé•·åº¦
        if article.title.count < 10 {
            warnings.append(ContentWarning(
                type: .spam,
                message: "æ¨™é¡ŒéŽçŸ­ï¼Œå¯èƒ½å½±éŸ¿é–±è®€é«”é©—",
                severity: .warning,
                location: "æ¨™é¡Œ"
            ))
        }
        
        // æª¢æŸ¥å…§å®¹é•·åº¦
        if article.fullContent.count < 200 {
            warnings.append(ContentWarning(
                type: .spam,
                message: "å…§å®¹éŽçŸ­ï¼Œå¯èƒ½ç¼ºä¹å¯¦è³ªå…§å®¹",
                severity: .warning,
                location: "æ­£æ–‡"
            ))
        }
        
        // æª¢æŸ¥æ‘˜è¦æ˜¯å¦åˆé©
        if article.summary.isEmpty {
            warnings.append(ContentWarning(
                type: .dataAccuracy,
                message: "ç¼ºå°‘æ–‡ç« æ‘˜è¦",
                severity: .info,
                location: "æ‘˜è¦"
            ))
        }
        
        return warnings
    }
    
    /// é‡‘èžå»ºè­°é¢¨éšªæª¢æŸ¥
    private func checkFinancialAdviceRisk(_ article: Article) -> [ContentWarning] {
        var warnings: [ContentWarning] = []
        let content = "\(article.title) \(article.summary) \(article.fullContent)".lowercased()
        
        let adviceKeywords = riskKeywords["financial_advice"] ?? []
        
        for keyword in adviceKeywords {
            if content.contains(keyword.lowercased()) {
                warnings.append(ContentWarning(
                    type: .financialAdvice,
                    message: "åŒ…å«å¯èƒ½æ§‹æˆæŠ•è³‡å»ºè­°çš„å…§å®¹ï¼šã€Œ\(keyword)ã€",
                    severity: .warning,
                    location: "å…§å®¹æª¢æŸ¥"
                ))
            }
        }
        
        return warnings
    }
    
    /// é—œéµå­—é¢¨éšªæª¢æŸ¥
    private func checkRiskKeywords(_ article: Article) -> [ContentWarning] {
        var warnings: [ContentWarning] = []
        let content = "\(article.title) \(article.summary) \(article.fullContent)".lowercased()
        
        // æª¢æŸ¥ä¸ç•¶å…§å®¹
        let inappropriateKeywords = riskKeywords["inappropriate"] ?? []
        for keyword in inappropriateKeywords {
            if content.contains(keyword.lowercased()) {
                warnings.append(ContentWarning(
                    type: .inappropriateLanguage,
                    message: "åŒ…å«æ•æ„Ÿè©žå½™ï¼šã€Œ\(keyword)ã€",
                    severity: .error,
                    location: "å…§å®¹æª¢æŸ¥"
                ))
            }
        }
        
        return warnings
    }
    
    /// æ•¸æ“šæº–ç¢ºæ€§æª¢æŸ¥
    private func checkDataAccuracy(_ article: Article) -> [ContentWarning] {
        var warnings: [ContentWarning] = []
        
        // æª¢æŸ¥æ˜¯å¦åŒ…å«å…·é«”æ•¸æ“šä½†ç¼ºä¹ä¾†æº
        let content = article.fullContent
        let hasNumbers = content.range(of: #"\d+(\.\d+)?%"#, options: .regularExpression) != nil
        
        if hasNumbers && !content.lowercased().contains("è³‡æ–™ä¾†æº") && !content.lowercased().contains("æ•¸æ“šä¾†æº") {
            warnings.append(ContentWarning(
                type: .dataAccuracy,
                message: "åŒ…å«æ•¸æ“šä½†ç¼ºä¹ä¾†æºæ¨™è¨»",
                severity: .warning,
                location: "æ•¸æ“šå¼•ç”¨"
            ))
        }
        
        return warnings
    }
    
    /// æ³•è¦åˆè¦æª¢æŸ¥
    private func checkRegulatoryCompliance(_ article: Article) -> [ContentWarning] {
        var warnings: [ContentWarning] = []
        
        // æª¢æŸ¥æ˜¯å¦éœ€è¦é¢¨éšªè­¦ç¤º
        let content = "\(article.title) \(article.summary) \(article.fullContent)".lowercased()
        
        if content.contains("è‚¡ç¥¨") || content.contains("æŠ•è³‡") || content.contains("åŸºé‡‘") {
            if !content.contains("é¢¨éšª") && !content.contains("è™§æ") {
                warnings.append(ContentWarning(
                    type: .regulatory,
                    message: "æŠ•è³‡ç›¸é—œå…§å®¹å»ºè­°åŠ å…¥é¢¨éšªè­¦ç¤º",
                    severity: .info,
                    location: "æ³•è¦åˆè¦"
                ))
            }
        }
        
        return warnings
    }
    
    /// è¨ˆç®—é¢¨éšªç­‰ç´š
    private func calculateRiskLevel(warnings: [ContentWarning]) -> ContentRiskLevel {
        let criticalCount = warnings.filter { $0.severity == .critical }.count
        let errorCount = warnings.filter { $0.severity == .error }.count
        let warningCount = warnings.filter { $0.severity == .warning }.count
        
        if criticalCount > 0 {
            return .critical
        } else if errorCount > 2 {
            return .high
        } else if errorCount > 0 || warningCount > 3 {
            return .medium
        } else {
            return .low
        }
    }
    
    /// è¨ˆç®—å¯©æ ¸åˆ†æ•¸
    private func calculateModerationScore(warnings: [ContentWarning], riskLevel: ContentRiskLevel) -> Double {
        var score = 1.0
        
        for warning in warnings {
            switch warning.severity {
            case .critical:
                score -= 0.3
            case .error:
                score -= 0.2
            case .warning:
                score -= 0.1
            case .info:
                score -= 0.05
            }
        }
        
        // æ ¹æ“šé¢¨éšªç­‰ç´šèª¿æ•´
        switch riskLevel {
        case .critical:
            score *= 0.3
        case .high:
            score *= 0.6
        case .medium:
            score *= 0.8
        case .low:
            break
        }
        
        return max(0.0, min(1.0, score))
    }
    
    /// ç”Ÿæˆæ”¹é€²å»ºè­°
    private func generateSuggestions(warnings: [ContentWarning]) -> [String] {
        var suggestions: [String] = []
        
        let warningTypes = Set(warnings.map { $0.type })
        
        for type in warningTypes {
            switch type {
            case .financialAdvice:
                suggestions.append("å»ºè­°ä½¿ç”¨æ›´ä¸­æ€§çš„èªžè¨€ï¼Œé¿å…ç›´æŽ¥çš„æŠ•è³‡å»ºè­°")
            case .inappropriateLanguage:
                suggestions.append("è«‹æª¢æŸ¥ä¸¦ä¿®æ”¹å¯èƒ½ä¸ç•¶çš„ç”¨è©ž")
            case .dataAccuracy:
                suggestions.append("å»ºè­°ç‚ºå¼•ç”¨çš„æ•¸æ“šæ·»åŠ å¯é ä¾†æº")
            case .regulatory:
                suggestions.append("è€ƒæ…®æ·»åŠ é©ç•¶çš„é¢¨éšªè­¦ç¤ºè²æ˜Ž")
            case .spam:
                suggestions.append("å»ºè­°å¢žåŠ æ›´å¤šå¯¦è³ªæ€§å…§å®¹ä»¥æå‡æ–‡ç« å“è³ª")
            default:
                break
            }
        }
        
        if suggestions.isEmpty {
            suggestions.append("å…§å®¹æ•´é«”è‰¯å¥½ï¼Œå»ºè­°ç¹¼çºŒä¿æŒå°ˆæ¥­æ€§å’Œå®¢è§€æ€§")
        }
        
        return suggestions
    }
    
    /// ä¿å­˜å¯©æ ¸è¨˜éŒ„
    private func saveModerationRecord(_ record: ModerationRecord) async throws {
        // é€™è£¡å¯ä»¥å¯¦ç¾å°‡å¯©æ ¸è¨˜éŒ„ä¿å­˜åˆ°è³‡æ–™åº«çš„é‚è¼¯
        print("ðŸ“‹ [AIContentModerationService] ä¿å­˜å¯©æ ¸è¨˜éŒ„: \(record.articleTitle)")
    }
}

// MARK: - å¯©æ ¸è¨˜éŒ„
struct ModerationRecord: Identifiable {
    let id = UUID()
    let articleId: UUID
    let articleTitle: String
    let result: ContentModerationResult
    let moderatedAt: Date
    let moderator: String
}

// MARK: - å¯©æ ¸çµ±è¨ˆ
struct ModerationStats {
    let totalReviewed: Int
    let approved: Int
    let autoPublished: Int
    let riskDistribution: [ContentRiskLevel: Int]
    
    var approvalRate: Double {
        guard totalReviewed > 0 else { return 0 }
        return Double(approved) / Double(totalReviewed)
    }
    
    var autoPublishRate: Double {
        guard approved > 0 else { return 0 }
        return Double(autoPublished) / Double(approved)
    }
}